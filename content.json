{"meta":{"title":"CVNO-Blog","subtitle":"何以解忧","description":"何以解忧","author":"CVNO","url":"https://cvno.github.io"},"pages":[{"title":"categories","date":"2017-12-18T07:21:56.000Z","updated":"2017-12-18T07:22:19.000Z","comments":true,"path":"categories/index.html","permalink":"https://cvno.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-18T07:20:12.000Z","updated":"2017-12-18T07:21:44.000Z","comments":true,"path":"tags/index.html","permalink":"https://cvno.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"google voice keep","slug":"google-voice-keep","date":"2018-01-29T02:26:49.000Z","updated":"2018-02-01T02:37:12.000Z","comments":true,"path":"2018/01/google-voice-keep.html","link":"","permalink":"https://cvno.github.io/2018/01/google-voice-keep.html","excerpt":"","text":"项目地址: Google Voice Keep 项目更新记录2018-1-29 基本功能完成 提供为期半年的 SMS 订阅服务","categories":[{"name":"Project","slug":"Project","permalink":"https://cvno.github.io/categories/Project/"}],"tags":[]},{"title":"加密解密-[AES-RSA]","slug":"aes-rsa-jiami-jiemi","date":"2018-01-19T03:17:44.000Z","updated":"2018-01-30T08:04:02.000Z","comments":true,"path":"2018/01/aes-rsa-jiami-jiemi.html","link":"","permalink":"https://cvno.github.io/2018/01/aes-rsa-jiami-jiemi.html","excerpt":"","text":"RSA加密数据长度是有限制的 123456789101112131415161718192021222324252627282930313233343536373839import rsaimport base64 # ######### 1. 生成公钥私钥 #########pub_key_obj, priv_key_obj = rsa.newkeys(256) pub_key_str = pub_key_obj.save_pkcs1()pub_key_code = base64.standard_b64encode(pub_key_str) priv_key_str = priv_key_obj.save_pkcs1()priv_key_code = base64.standard_b64encode(priv_key_str) print(pub_key_code)print(priv_key_code) # ######### 2. 加密 #########def encrypt(value): key_str = base64.standard_b64decode(pub_key_code) pk = rsa.PublicKey.load_pkcs1(key_str) val = rsa.encrypt(value.encode('utf-8'), pk) return val # ######### 3. 解密 #########def decrypt(value): key_str = base64.standard_b64decode(priv_key_code) pk = rsa.PrivateKey.load_pkcs1(key_str) val = rsa.decrypt(value, pk) return val # ######### 基本使用 #########if __name__ == '__main__': v = 'wupeiqi' v1 = encrypt(v) print(v1) v2 = decrypt(v1) print(v2) 参考资料 https://www.cnblogs.com/52python/p/6589869.html AES加密数据长度无限制 12#3.6安装 pip3 install pycryptodome#mac pip3 install pycrypto 123456789101112131415161718192021222324252627282930############################### 加密 ############################## from Crypto.Cipher import AESdef encrypt(message): key = b'dfdsdfsasdfdsdfs' # key必须是16的整数倍 cipher = AES.new(key, AES.MODE_CBC, key) # 创建对象 # ---------------------------------------------- # 先转成字节,把数据拼够16字节的整数倍 ba_data = bytearray(message, encoding='utf-8') # 把数据转成bytearray(byte的数组),bytearray只能追加数字,默认把数字转成字节 v1 = len(ba_data) v2 = v1 % 16 if v2 == 0: # 保证收据长度是 16 的时候数据还是加密的 v3 = 16 else: v3 = 16 - v2 # v3是追加的长度 for i in range(v3): ba_data.append(v3) # bytearray只能追加数字,默认把数字转成字节 final_data = ba_data.decode('utf-8') # ---------------------------------------------- msg = cipher.encrypt(final_data) # 要加密的字符串，必须是16个字节或16个字节的倍数,加密后是byte格式 return msg############################### 解密 ##############################def decrypt(msg): key = b'dfdsdfsasdfdsdfs' cipher = AES.new(key, AES.MODE_CBC, key) result = cipher.decrypt(msg) # 把加密后的字节解密成不加密的字节 data = result[0:-result[-1]] return str(data, encoding='utf-8') 安装 https://github.com/sfbahr/PyCrypto-Wheels","categories":[],"tags":[]},{"title":"基于 GV 的 Python api","slug":"GV-python-api","date":"2018-01-15T05:25:59.000Z","updated":"2018-02-01T06:59:43.000Z","comments":true,"path":"2018/01/GV-python-api.html","link":"","permalink":"https://cvno.github.io/2018/01/GV-python-api.html","excerpt":"","text":"使用 Python3 来操作 Google Voice 的 API。 Git: code here 2018-02-01 修复重写某些方法时的 bug 2018-01-15 代码发布功能列表: 发送 SMS 拨打电话 取消拨打电话 标记为已读或未读 下载语音留言 后台自动检测是否有新信息 根据 SMS 的设置自动回复 它也可能是一个廉价的短信验证码方案，目前国内至少有两家大型的互联网公司使用这种方案。 依赖模块: pip install selenium pip install requests pip install BeautifulSoup PhantomJS 一款无界面模拟浏览器, 不同的操作系统安装方法有差异","categories":[{"name":"Project","slug":"Project","permalink":"https://cvno.github.io/categories/Project/"}],"tags":[]},{"title":"Phantomjs","slug":"Phantomjs","date":"2018-01-04T03:49:30.000Z","updated":"2018-01-04T03:57:47.000Z","comments":true,"path":"2018/01/Phantomjs.html","link":"","permalink":"https://cvno.github.io/2018/01/Phantomjs.html","excerpt":"","text":"无法打开https网站用 phantomjs 自动登陆并爬取一些数据，发现爬取 https 类型的网站的时候无法正常操作 Phantomjs中有个service_args参数可以忽略https错误 1driver = webdriver.PhantomJS(desired_capabilities=cap, service_args=['--ignore-ssl-errors=true']) 获取 cookie123456789101112131415from selenium import webdriverimport pickledriver=webdriver.PhantomJS()driver.get(url) #此处url填写需要访问的地址# 获得 cookie信息cookie_list = driver.get_cookies()print (cookie_list)cookie_dict = &#123;&#125;for cookie in cookie_list: #写入文件 f = open('cookie.txt','wb+') pickle.dump(cookie, f) f.close() cookie_dict[cookie['name']] = cookie['value'] 引用 http://www.cnblogs.com/fly-kaka/p/6656196.html https://www.cnblogs.com/Jacck/p/7675284.html","categories":[],"tags":[{"name":"Phantomjs","slug":"Phantomjs","permalink":"https://cvno.github.io/tags/Phantomjs/"}]},{"title":"设计模式","slug":"design-patterns","date":"2018-01-03T08:18:23.000Z","updated":"2018-01-09T06:38:33.000Z","comments":true,"path":"2018/01/design-patterns.html","link":"","permalink":"https://cvno.github.io/2018/01/design-patterns.html","excerpt":"","text":"什么是设计模式Christopher Alexander:“每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的解决方案的核心。这样你就能一次又一次地使用该方案而不必做重复劳动。” 每一个设计模式系统地命名、解释和评价了面向对象系统中一个重要的和重复出现的设计。 GoF（Gang of Four） 设计模式四个基本要素：模式名称、问题、解决方案、效果 面向对象的三大特性: 封装：把数据和函数包装在类里 类的边界限制了一些外界的访问 继承：复用 多态：多态语言 1234567891011121314151617181920212223242526272829303132# 封装class A: def __init__(self, x): self.__test = x # 私有变量 def gettest(self): return self.__test def settest(self, x): self.__test = x# 继承：复用class B(A): def __init__(self): pass # override 重写 覆写 def settest(self): self.__test = x + 1# 多态 python 是一种多态语言# 一个函数的多种表现# 重载 python 不支持def test(x, y): return x+ydef test(x, y, z): return x+y+ztest(2,3)test(2,3,4) 接口一种特殊的类（抽象类），声明了若干方法，要求继承该接口的类必须实现这些方法。目的就是对外保持一致 作用：限制继承接口的类的方法的名称及调用方式；隐藏了类的内部实现。 接口就是一种抽象的基类（父类），限制继承它的类必须实现接口中定义的某些方法 其实就是限制程序员的东西, 不能乱写, 按照定的规范去写 示例 12345678910111213141516171819202122232425262728# 接口的两种写法# 1.class A: def test(self): raise NotImplementedError # 限制 子类必须实现class B(A): def test(self): print('B.test')# 2. 抽象类不能实例化 from abs import bastractmethod,ABCMeta class A(metaclass=ABCMeta): # 抽象类 @abstractmethod def test(self): # 抽象方法 必须在子类实现 raise NotImplementedError # 限制 子类必须实现class B(A): passclass C(A): def test(self): print('B.test')a = B() # 不能实例化b = C() # 可以实例化 设计模式六大原则开闭原则一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 里氏（Liskov）替换原则所有引用基类（父类）的地方必须能透明地使用其子类的对象。功能保持一致 依赖倒置原则高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。换言之，要针对接口（抽象）编程，而不是针对实现（实例）编程。 接口隔离原则使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。（多继承）示例 迪米特法则一个软件实体应当尽可能少地与其他实体发生相互作用。解耦 五大原则没有这个迪米特法则 单一职责原则不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 一个类（class）只干一件事 合成复用原则 尽量使用合成／聚合的方式，而不是继承。示例 合成 复用 继承 的使用分情况而定 设计模式创建型模式工厂方法模式定义一个用于创建对象的接口（工厂接口），让子类决定实例化哪一个产品类。角色： 抽象工厂角色（Creator） 具体工厂角色（Concrete Creator） 抽象产品角色（Product） 具体产品角色（Concrete Product） 工厂方法模式相比简单工厂模式将每个具体产品都对应了一个具体工厂。 示例 适用场景： 需要生产多种、大量复杂对象的时候 需要降低耦合度的时候 当系统中的产品种类需要经常扩展的时候 优点： 每个具体产品都对应一个具体工厂类，不需要修改工厂类代码 隐藏了对象创建的实现细节 缺点： 每增加一个具体产品类，就必须增加一个相应的具体工厂类 简单工厂模式不直接向客户端暴露对象创建的实现细节，而是通过一个工厂类来负责创建产品类的实例。角色： 工厂角色（Creator） 抽象产品角色（Product） 具体产品角色（Concrete Product） 优点： 隐藏了对象创建的实现细节 客户端不需要修改代码 缺点：违反了单一职责原则，将创建逻辑集中到一个工厂类里当添加新产品时，需要修改工厂类代码，违反了开闭原则 示例 单例模式比如: 数据库连接 好的单列模式会写一个基类（示例） 单例（Singleton）: 保证一个类只有一个实例，并提供一个访问它的全局访问点。 适用场景: 当类只能有一个实例而且客户可以从一个众所周知的访问点访问它时 优点: 对唯一实例的受控访问 单例相当于全局变量，但防止了命名空间被污染 与单例模式功能相似的概念：全局变量、静态变量（方法） 1234567891011class A: test = 0 A.test = 1a = A()print(a.test)# a.test = 1 # 对象变量的修改不会影响到类的静态变量b = A()print(b.test) 抽象工厂模式定义一个工厂类接口，让工厂子类来创建一系列相关或相互依赖的对象。例：生产一部手机，需要手机壳、CPU、操作系统三类对象进行组装，其中每类对象都有不同的种类。对每个具体工厂，分别生产一部手机所需要的三个对象。 角色： 示例 抽象工厂角色（Creator） 具体工厂角色（Concrete Creator） 抽象产品角色（Product） 具体产品角色（Concrete Product） 客户端（Client) 相比工厂方法模式，抽象工厂模式中的每个具体工厂都生产一套产品。 适用场景： 系统要独立于产品的创建与组合时 强调一系列相关的产品对象的设计以便进行联合使用时 提供一个产品类库，想隐藏产品的具体实现时 优点： 将客户端与类的具体实现相分离 每个工厂创建了一个完整的产品系列，使得易于交换产品系列 有利于产品的一致性（即产品之间的约束关系） 缺点： 难以支持新种类的（抽象）产品 建造者模式将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 角色： 抽象建造者（Builder） 具体建造者（Concrete Builder） 指挥者（Director） 产品（Product） 建造者模式与抽象工厂模式相似，也用来创建复杂对象。主要区别是建造者模式着重一步步构造一个复杂对象，而抽象工厂模式着重于多个系列的产品对象。 示例 适用场景： 当创建复杂对象的算法（Director）应该独立于该对象的组成部分（Builder）时 当构造过程允许被构造的对象有不同的表示时（不同Builder）。 优点： 隐藏了一个产品的内部结构和装配过程 将构造代码与表示代码分开 可以对构造过程进行更精细的控制 小结 使用 Abstract Factory（抽象工厂）、Prototype（原型模式） 或 Builder（建造者） 的设计甚至比使用 Factory Method（工厂方法） 的那些设计更灵活，但它们也更加复杂。通常，设计以使用 Factory Method（简单工厂也可以） 开始，并且当设计者发现需要更大的灵活性时，设计便会向其他创建型模式演化。当你在设计标准之间进行权衡的时候，了解多个模式可以给你提供更多的选择余地。 也就是说，不用一开始就选好模式，先从简单的模式开始，如果需要频繁的改代码，就用工厂方法，等等…… 一步一步递进 依赖于继承的创建型模式：工厂方法模式依赖于组合的创建性模式：抽象工厂模式、创建者模式 结构型模式适配器模式将一个类的接口转换成客户希望的另一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。角色： 目标接口（Target） 待适配的类（Adaptee） 适配器（Adapter）(套壳) 两种实现方式： 类适配器：使用多继承 对象适配器：使用组合 示例 适用场景：想使用一个已经存在的类，而它的接口不符合你的要求（对象适配器）想使用一些已经存在的子类，但不可能对每一个都进行子类化以匹配它们的接口。对象适配器可以适配它的父类接口。 类适配器和对象适配器有不同的权衡。 类适配器 用一个具体的 Adapter 类对 Adaptee 和 Target 进行匹配。结果是当我们想要匹配一个类以及所有它的子类时，类 Adapter 将不能胜任工作。 使得 Adapter 可以重定义 Adaptee 的部分行为，因为 Adapter 是 Adaptee 的一个子类。 仅仅引入（继承）了一个对象，并不需要额外的指针以间接得到 adaptee。 对象适配器则 允许一个 Adapter 与多个 Adaptee-即 Adaptee 本身以及它的所有子类（如果有子类的话）一同时工作。Adapter 也可以一次给所有的 Adaptee 添加功能。 使得重定义 Adaptee 的行为比较困难。这就需要生成 Adaptee 的子类并且使得 Adapter 引用这个子类而不是引用 Adaptee 本身。 组合模式将对象组合成树形结构以表示“部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 二叉树的结构角色： 抽象组件（Component） 叶子组件（Leaf） 复合组件（Composite） 客户端（Client） 示例 适用场景： 表示对象的“部分-整体”层次结构（特别是结构是递归的） 希望用户忽略组合对象与单个对象的不同，用户统一地使用组合结构中的所有对象 优点： 定义了包含基本对象和组合对象的类层次结构 简化客户端代码，即客户端可以一致地使用组合对象和单个对象 更容易增加新类型的组件 缺点： 很难限制组合中的组件 代理模式为其他对象提供一种代理以控制对这个对象的访问。角色： 抽象实体（Subject） 实体（RealSubject） 代理（Proxy） 示例 适用场景： 远程代理：为远程的对象提供代理 虚代理：根据需要创建很大的对象 保护代理：控制对原始对象的访问，用于对象有不同访问权限时 优点： 远程代理：可以隐藏对象位于远程地址空间的事实 虚代理：可以进行优化，例如根据要求创建对象 保护代理：允许在访问一个对象时有一些附加的内务处理 行为型模式责任链模式使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。 角色： 抽象处理者（Handler） 具体处理者（ConcreteHandler） 客户端（Client） 示例 例：请假部门批准：leader -&gt; 部门经理 -&gt; 总经理Javascript事件浮升机制 适用场景： 有多个对象可以处理一个请求，哪个对象处理由运行时决定 在不明确接收者的情况下，向多个对象中的一个提交一个请求 优点： 降低耦合度：一个对象无需知道是其他哪一个对象处理其请求 缺点： 请求不保证被接收：链的末端没有处理或链配置错误 迭代器模式提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示 实现方法：__iter__、__next__ 示例 适用于封装数据结构,这种结构类似与列表,或树,封装数据类型,不让外人知道是怎么存的 观察者模式定义对象间的一种一对多的依赖关系,当一个对象的状态发生改变时, 所有依赖于它的对象都得到通知并被自动更新。观察者模式又称“发布-订阅”模式 角色： 抽象主题（Subject） 具体主题（ConcreteSubject）——发布者 抽象观察者（Observer） 具体观察者（ConcreteObserver）——订阅者 示例 适用场景： 当一个抽象模型有两方面，其中一个方面依赖于另一个方面。将这两者封装在独立对象中以使它们可以各自独立地改变和复用。 当对一个对象的改变需要同时改变其它对象，而不知道具体有多少对象有待改变。 当一个对象必须通知其它对象，而它又不能假定其它对象是谁。换言之，你不希望这些对象是紧密耦合的。 优点： 目标和观察者之间的耦合最小 支持广播通信 缺点： 多个观察者之间互不知道对方存在，因此一个观察者对主题的修改可能造成错误的更新。 策略模式定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。 角色： 抽象策略（Strategy） 具体策略（ConcreteStrategy） 上下文（Context） 示例 适用场景： 许多相关的类仅仅是行为有异 需要使用一个算法的不同变体 算法使用了客户端无需知道的数据 一个类中的多种行为以多个条件语句的形式存在，可以将这些行为封装如不同的策略类中。 优点： 定义了一系列可重用的算法和行为 消除了一些条件语句 可以提供相同行为的不同实现 缺点： 客户必须了解不同的策略 策略与上下文之间的通信开销 增加了对象的数目 模板方法模式定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 角色： 抽象类（AbstractClass）：定义抽象的原子操作（钩子操作）；实现一个模板方法作为算法的骨架。 具体类（ConcreteClass）：实现原子操作 示例 适用场景： 一次性实现一个算法的不变的部分 各个子类中的公共行为应该被提取出来并集中到一个公共父类中以避免代码重复 控制子类扩展 总结设计模式可互相嵌套, 如: 策略模式的算法写成单例模式比较好; 创建型模式都是对象怎么创建 结构型模式是怎么把类组织在一起 适配器模式类写坏了, 和其他类不适配 组合模式是几个类怎么表现一样, 叶子节点和复合节点怎么表现一样 代理模式提供几种代理, 以控制加权限, 或加内容 行为型模式是怎么做事, 方法函数怎么做 责任链模式, 一个一个传下去 迭代器模式, 一个一个拿元素处理 （应用面狭小） 观察者模式, 一个一个更新 加深理解工厂模式是什么？有什么用？怎么用？什么好处？ 哪个工厂模式,简单工厂模式，工厂方法模式还是抽象工厂模式。 简单工厂模式就是把所有产品的创建细节都隐藏在一个工厂里，也就是把要创建的这个类的对象的创建细节隐藏在工厂里，这就叫简单工厂。 问题：因为这个类所有的产品创建细节都隐藏在一个工厂里，那如果要加产品，就需要改工厂的代码，这个就不符合开闭原则。简单工厂的一个类，承载了很多产品的创建，所以不符合单一职责原则。就需要从简单工厂升级到工厂方法模式。 工厂方法模式就是是一个产品，一种产品的创建过程，它隐藏在一个单独的工厂里，每一个产品对应一个工厂，同样, 产品的创建过程隐藏在这个工厂里， 需要的注意的是：有多个工厂的时候，我们需要一个工厂的接口–抽象工厂，也就是工厂方法模式。工厂方法模式还是把对象的创建过程隐藏在了工厂里。它和之前简单工厂相比的话，一个产品对应一个工厂，加新产品的话，只需要再加一个工厂就可以了，不需要修改工厂代码。缺点就是加一个产品需要添加两类。类写的比较多，这是工厂方法模式。 抽象工厂模式和跟前面的两个就不太一样，它是生产一个产品系列，或者叫一套产品，生产一套产品的时候，一个工厂负责生产一套。好处: 第一，把对象的创建细节隐藏在工厂里, 第二, 可以保持产品系列的一致性，也就是加约束。 比如：苹果的IOS只能加苹果的手机壳，苹果CPU, 这就叫一致性，小产品之间的约束。 设计模式大全 创建型模式： 工厂方法模式 抽象工厂模式 创建者模式 原型模式 单例模式 结构型模式 适配器模式 桥模式 组合模式 装饰模式 外观模式 享元模式 代理模式 行为型模式 解释器模式 责任链模式 命令模式 迭代器模式 中介者模式 备忘录模式 观察者模式 状态模式 策略模式 访问者模式 模板方法模式","categories":[],"tags":[]},{"title":"设置django admin 显示为中文","slug":"django-admin-cn","date":"2018-01-02T09:54:22.000Z","updated":"2018-01-03T07:59:28.000Z","comments":true,"path":"2018/01/django-admin-cn.html","link":"","permalink":"https://cvno.github.io/2018/01/django-admin-cn.html","excerpt":"","text":"默认的 django admin 组件 显示为英文，设置 django admin 显示为中文很简单，只需在 settings.py 的 MIDDLEWARE_CLASSES 中添加一句 &#39;django.middleware.locale.LocaleMiddleware&#39; 即可。 如: 123456789MIDDLEWARE_CLASSES = ( &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;, &apos;django.middleware.common.CommonMiddleware&apos;, &apos;django.middleware.csrf.CsrfViewMiddleware&apos;, &apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;, &apos;django.contrib.messages.middleware.MessageMiddleware&apos;, &apos;django.middleware.clickjacking.XFrameOptionsMiddleware&apos;, &apos;django.middleware.locale.LocaleMiddleware&apos;,) 注意： &#39;django.middleware.locale.LocaleMiddleware&#39; 必须放在 &#39;django.contrib.sessions.middleware.SessionMiddleware&#39; 之后。 如果添加上面这句话后还是显示英文，则可能是浏览器语言设置问题，在浏览器语言设置中添加中文并放到首位试试。比如 Firefox 浏览器设置为：Firefox-&gt;Edit-&gt;Preferences-&gt; Content-&gt;Languages 引用 https://my.oschina.net/means/blog/287753","categories":[],"tags":[{"name":"django","slug":"django","permalink":"https://cvno.github.io/tags/django/"}]},{"title":"Docker 操作","slug":"my-docker-note","date":"2018-01-02T02:48:30.000Z","updated":"2018-01-03T14:02:52.000Z","comments":true,"path":"2018/01/my-docker-note.html","link":"","permalink":"https://cvno.github.io/2018/01/my-docker-note.html","excerpt":"","text":"why? 更高效的利用系统资源 更快速的启动时间 一致的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 基本概念 镜像（Image） 容器（Container） 仓库（Repository） 理解了这三个概念，就理解了 Docker 的整个生命周期。 获取镜像从 Docker 镜像仓库获取镜像的命令是 docker pull。其命令格式为： 1docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 如: 123456789$ docker pull ubuntu:16.0416.04: Pulling from library/ubuntubf5d46315322: Pull complete9f13e0ac480c: Pull completee8988b5b3097: Pull complete40af181810e7: Pull completee6f7c7e5c03e: Pull completeDigest: sha256:147913621d9cdea08853f6ba9116c2e27a3ceffecf3b492983ae97c3d643fbbeStatus: Downloaded newer image for ubuntu:16.04 运行1$ docker run -it --rm ubuntu:16.04 bash 说明一下上面用到的参数。 -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 –rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 –rm 可以避免浪费空间。 ubuntu:16.04：这是指用 ubuntu:16.04 镜像为基础来启动容器。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 进入容器后，我们可以在 Shell 下操作，执行任何所需的命令。这里，我们执行了 cat /etc/os-release，这是 Linux 常用的查看当前系统版本的命令，从返回的结果可以看到容器内是 Ubuntu 16.04.4 LTS 系统。 启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器重新启动。 因为 Docker 的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 新建并启动 无交互 12$ docker run ubuntu:14.04 /bin/echo 'Hello world'Hello world 允许交互 12$ docker run -t -i ubuntu:14.04 /bin/bashroot@af8bae53bdd3:/# 其中，-t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开。 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动已终止容器可以利用 docker container start 命令，直接将一个已经终止的容器启动运行。 容器的核心为所执行的应用程序，所需要的资源都是应用程序运行所必需的。除此之外，并没有其它的资源。可以在伪终端中利用 ps 或 top 来查看进程信息。 1234root@ba267838cc1b:/# ps PID TTY TIME CMD 1 ? 00:00:00 bash 11 ? 00:00:00 ps 可见，容器中仅运行了指定的 bash 应用。这种特点使得 Docker 对资源的利用率极高，是货真价实的轻量级虚拟化。 后台运行需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。可以通过添加 -d 参数来实现。 不使用 -d 参数运行容器。 容器会把输出的结果 (STDOUT) 打印到宿主机上面 使用了 -d 参数运行容器。 12$ docker run -d ubuntu:17.10 /bin/sh -c \"while true; do echo hello world; sleep 1; done\"77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a 此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 docker logs 查看)。容器是否会长久运行，是和 docker run 指定的命令有关，和 -d 参数无关。 使用 -d 参数启动后会返回一个唯一的 id，也可以通过 docker container ls 命令来查看容器信息。 123$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES77b2dc01fe0f ubuntu:17.10 /bin/sh -c 'while tr 2 minutes ago Up 1 minute agitated_wright 要获取容器的输出信息，可以通过 docker container logs 命令。 12345$ docker container logs [container ID or NAMES]hello worldhello worldhello world. . . 终止容器可以使用 docker container stop 来终止一个运行中的容器。 此外，当 Docker 容器中指定的应用终结时，容器也自动终止。 用户通过 exit 命令或 Ctrl+d 来退出终端时，所创建的容器立刻终止。 终止状态的容器可以用 docker container ls -a 命令看到。例如 1234docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESba267838cc1b ubuntu:14.04 \"/bin/bash\" 30 minutes ago Exited (0) About a minute ago trusting_newton98e5efa7d997 training/webapp:latest \"python app.py\" About an hour ago Exited (0) 34 minutes ago backstabbing_pike 处于终止状态的容器，可以通过 docker container start 命令来重新启动。 重新启动1$ docker container restart 此外，docker container restart 命令会将一个运行态的容器终止，然后再重新启动它。 进入容器在使用 -d 参数时，容器启动后会进入后台。 某些时候需要进入容器进行操作，包括使用 docker attach 命令或 docker exec 命令，推荐大家使用 docker exec 命令，因为使用 attach stdin 执行 exit 会导致容器停止。 attach 命令docker attach 是 Docker 自带的命令。下面示例如何使用该命令。 123456789$ docker run -dit ubuntu243c32535da7d142fb0e6df616a3c3ada0b8ab417937c853a9e1c251f499f550$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES243c32535da7 ubuntu:latest \"/bin/bash\" 18 seconds ago Up 17 seconds nostalgic_hypatia$ docker attach 243croot@243c32535da7:/# exec 命令-i -t 参数docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。 只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。 当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。 12345678910111213141516$ docker run -dit ubuntu69d137adef7a8a689cbcb059e94da5489d3cddd240ff675c640c8d96e84fe1f6$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES69d137adef7a ubuntu:latest \"/bin/bash\" 18 seconds ago Up 17 seconds zealous_swirles$ docker exec -i 69d1 bashlsbinbootdev...$ docker exec -it 69d1 bashroot@69d137adef7a:/# 导出和导入容器导出容器如果要导出本地某个容器，可以使用 docker export 命令。 1234$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7691a814370e ubuntu:14.04 \"/bin/bash\" 36 hours ago Exited (0) 21 hours ago test$ docker export 7691a814370e &gt; ubuntu.tar 导入容器快照可以使用 docker import 从容器快照文件中再导入为镜像，例如 1234$ cat ubuntu.tar | docker import - test/ubuntu:v1.0$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEtest/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外，也可以通过指定 URL 或者某个目录来导入，例如 1$ docker import http://example.com/exampleimage.tgz example/imagerepo 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 删除删除容器12$ docker container rm trusting_newtontrusting_newton 如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器。 清理所有处于终止状态的容器用 docker container ls -a 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多要一个个删除可能会很麻烦，用下面的命令可以清理掉所有处于终止状态的容器。 1$ docker container prune 常用操作1234$ docker --version # docker版本$ docker info # docker信息$ docker run --rm ubuntu:16.04 /bin/cat '/etc/os-release'$ docker run -it --name web --rm ubuntu:16.04 bash 停止容器12➜ docker stop myUbuntumyUbuntu 删除容器12➜ docker rm myUbuntumyUbuntu 列出镜像1234➜ docker images lsREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 6b914bbcb89e 3 weeks ago 182 MBubuntu 14.04 7c09e61e9035 3 weeks ago 188 MB 列出部分镜像12$ docker image ls ubuntu$ docker image ls ubuntu:16.04 docker image ls 还支持强大的过滤器参数 –filter，或者简写 -f 12$ docker image ls -f since=mongo:3.2$ docker image ls -f 想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可。 如果定义了 LABEL，还可以通过 LABEL 来过滤 1label=com.example.version=0.1 以特定格式显示123$ docker image ls -q$ docker image ls --format \"&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;\"$ docker image ls --format \"table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;\" 删除镜像1234$ docker rmi 7c09e61e9035Untagged: ubuntu:14.04Untagged: ...$ docker image rm $(docker image ls -q redis) 查看容器修改内容1234$ docker diff webserverC /rootA /root/.bash_history... 查看docker进程12➜ ~ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES nginx1$ docker run --name webserver -d -p 80:80 nginx 引用 http://blog.csdn.net/zhengyong15984285623/article/details/66971949 https://yeasy.gitbooks.io/docker_practice/","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://cvno.github.io/tags/docker/"}]},{"title":"数据结构基础","slug":"data-structure-basis","date":"2017-12-26T12:58:31.000Z","updated":"2017-12-26T13:33:27.000Z","comments":true,"path":"2017/12/data-structure-basis.html","link":"","permalink":"https://cvno.github.io/2017/12/data-structure-basis.html","excerpt":"","text":"概念数据结构是设计数据以何种方式组织并存储在计算机中。 比如：列表、集合与字典等都是一种数据结构。 详细的说： 物理层面：就是以什么样的物理存储方式 逻辑方式：列表，字典，集合，树 线性数据结构，树形数据结构，图形数据结构， 基本是线性数据结构 N.Wirth: “程序=数据结构+算法” 列表列表：在其他编程语言中称为“数组”，是一种基本的数据结构类型。如果更学术一点的说法是“线性表”。 数组与列表的不同之处：数组是定长的数组，如果开的内存空间长度为7，就不能再追加，只能存7个，并且这7个元素类型还必须是一样的 数组：定长，元素类型统一。 Python中的给一个列表，开一块连续内存空间，开的内存空间的长度不会刚好是列表的长度，一定会多，而内存中：变量指向的列表的元素存的是一个个内存地址（地址的格子才是真正存元素值的地方），每个元素占用的空间都是一样的，大部分编译型的语言直接存的值，而python存的不是值，而是值的内存地址。 Python中一直append值的原理：如果之前的空间不够，就再开时原来一倍的内存空间，然后把旧的删掉 列表li[2]寻址的时候是li+2*内存地址的字节 32位机器一个地址4个子节64位机器一个地址8个字节 关于列表的问题： 列表中元素使如何存储的？(上述) 列表提供了哪些基本的操作？(下标查找，插入，删除) 这些操作的时间复杂度是多少？ O(1) O(n)(插入的时候，插入位置之后的值都需要往后挪) 链表链表中每一个元素都是一个对象，每个对象称为一个节点，包含有数据域key和指向下一个节点的指针next。通过各个节点之间的相互连接，最终串联成一个链表。 为什么用链表？链表的插入和删除特别快 节点定义: 1234567891011121314class Node(object): def __init__(self,item): self.item = item self.next = Nonen1 = Node(1)n2 = Node(2)n3 = Node(3)n1.next = n2n2.next = n3print(n1.next.item) # 2print(n1.next.next.item) # 3 头节点 链表的遍历 12345def traversal(head): curNode = head # 临时用指针 while curNode is not None: print(curNode.data) curNode = curNode.next 链表节点的插入和删除O1的时间复杂度 插入 12p.next = curNode.nextcurNode.next = p 删除 1234p = curNode.nextcurNode.next = curNode.next.next# 也可以 &gt;&gt; curNode.next = p.nextdel p 建立链表 头插法 1234567def createLinkList(li): l = Node() for num in li: s = Node(Num) s.next = l.next l.next = s return l 尾插法 1234567def createLinkList(li): l = Node() r = l # r 指向尾节点 for num in li : s = Node(num) r.next = s r = s 双链表双链表中每个节点有两个指针：一个指向后面节点、一个指向前面节点。 节点定义： 12345class Node(object): def __init__(self,item = None): self.item = item self.next = None self.prior = None 双链表节点的插入和删除 插入 1234p.next = curNode.nextcurNode.next.prior = pp.prior = curNodecurNode.next = p 删除 1234p = curNode.nextcurNode.next = p.nextp.next.prior = curNodedel p 链表分析列表与链表 按元素值查找（链表二分是On的复杂度） 按下标查找（链表没有法用下表查找，李列表：O1，链表On） 在某元素后插入（列表：On，链表：O1） 删除某元素（列表：On，链表：O1） 树也是以链表的形式存 栈栈(Stack)是一个数据集合，可以理解为只能在一端进行插入或删除操作的列表。 特点： 后进先出（last-in, first-out）LIFO 概念： 栈顶 栈底 基本操作： 进栈（压栈）：push 出栈：pop 取栈顶：gettop 应用实例： Word 的撤销操作（撤销的时候后边的操作） 重做 两个栈,撤销栈出栈，重做栈压栈；重做操作是记录撤销操作的。 栈的简单实现(Python)不需要自己定义，使用列表结构即可。 进栈函数：append 出栈函数：pop 查看栈顶函数：li[-1] 栈的应用 - 括号匹配问题给一个字符串，其中包含小括号、中括号、大括号，求该字符串中的括号是否匹配。 ()()[]{} 匹配 ([{()}]) 匹配 []( 不匹配 [(]) 不匹配 代码补全，当栈是空的，栈才是合法的 代码实现括号匹配 队列队列(Queue)是一个数据集合，仅允许在列表的一端进行插入，另一端进行删除。 进行插入的一端称为队尾(rear)，插入动作称为进队或入队 进行删除的一端称为队头(front)，删除动作称为出队 队列的性质：先进先出(First-in, First-out) 双向队列：队列的两端都允许进行进队和出队操作。 队列的实现用Python的列表来实现出队复杂度太高 123456使用方法：from collections import deque- 创建队列：queue = deque(li)- 进队：append- 出队：popleft- 双向队列队首进队：appendleft- 双向队列队尾进队：pop 实现原理 初步设想：列表+两个下标指针 创建一个列表和两个变量，front变量指向队首，rear变量指向队尾。初始时，front和rear都为0。 进队操作：元素写到li[rear]的位置，rear自增1。 出队操作：返回li[front]的元素，front自减1。 环形队列环形队列：当队尾指针front == Maxsize + 1时，再前进一个位置就自动到0。实现方式：求余数运算 队首指针前进1：front = (front + 1) % MaxSize 队尾指针前进1：rear = (rear + 1) % MaxSize 队空条件：rear == front 队满条件：(rear + 1) % MaxSize == front 代码实现 通过Python自带库 手写循环队列 123456789101112import queue # 线程同步######## 分割 ########from collections import dequequeue = deque()queue.append(1)queue.append(2)queue.append(3)print( ())print(queue.popleft())######## 分割 ########queue.appendleft(2)queue.pop() 哈希表Python中的集合与字典哈希表查找 哈希表（Hash Table，又称为散列表），是一种线性表的存储结构。通过把每个对象的关键字k作为自变量，通过一个哈希函数h(k)，将k映射到下标h(k)处，并将该对象存储在这个位置。 例如：数据集合{1,6,7,9}，假设存在哈希函数h(x)使得h(1) = 0, h(6) = 2, h(7) = 4, h(9) = 5，那么这个哈希表被存储为[1,None, 6, None, 7, 9]。 当我们查找元素6所在的位置时，通过哈希函数h(x)获得该元素所在的下标（h(6) = 2），因此在2位置即可找到该元素。 12345li = [1,2,3,4]s = &#123;1,2,3,4&#125; # 集合的效率更高# 哈希函数设计的再好也避免不了碰撞## 哈希冲突哈希冲突：由于哈希表的下标范围是有限的，而元素关键字的值是接近无限的，因此可能会出现h(102) = 56， h(2003) = 56这种情况。此时，两个元素映射到同一个下标处，造成哈希冲突。 解决哈希冲突 拉链法（将所有冲突的元素用链表连接） 开放寻址法（通过哈希冲突函数得到新的地址） 字典在Python中的字典： 1a = &#123;&apos;name&apos;: &apos;Alex&apos;, &apos;age&apos;: 18, &apos;gender&apos;: &apos;Man&apos;&#125; 使用哈希表存储字典，通过哈希函数将字典的键映射为下标。假设h(‘name’) = 3, h(‘age’) = 1, h(‘gender’) = 4，则哈希表存储为[None, 18, None, ’Alex’, ‘Man’] 在字典键值对数量不多的情况下，几乎不会发生哈希冲突，此时查找一个元素的时间复杂度为O(1)。 迷宫问题给一个二维列表，表示迷宫（0表示通道，1表示围墙）。给出算法，求一条走出迷宫的路径。 栈 栈-方案 深度优先 DFS（Depth[栈]-First-Search） 队列 队列-方案 使用二维列表存储多条路径如何是打印出路径是难点 123456789101112maze = [ [1,1,1,1,1,1,1,1,1,1], [1,0,0,1,0,0,0,1,0,1], [1,0,0,1,0,0,0,1,0,1], [1,0,0,0,0,1,1,0,0,1], [1,0,1,1,1,0,0,0,0,1], [1,0,0,0,1,0,0,0,0,1], [1,0,1,0,0,0,1,0,0,1], [1,0,1,1,1,0,1,1,0,1], [1,1,0,0,0,0,0,0,0,1], [1,1,1,1,1,1,1,1,1,1]] 本文代码及 md 文件 Github","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://cvno.github.io/categories/数据结构/"}],"tags":[{"name":"链表","slug":"链表","permalink":"https://cvno.github.io/tags/链表/"},{"name":"栈","slug":"栈","permalink":"https://cvno.github.io/tags/栈/"},{"name":"队列","slug":"队列","permalink":"https://cvno.github.io/tags/队列/"},{"name":"哈希表","slug":"哈希表","permalink":"https://cvno.github.io/tags/哈希表/"},{"name":"迷宫","slug":"迷宫","permalink":"https://cvno.github.io/tags/迷宫/"}]},{"title":"TOP 榜单算法（nlargest）","slug":"top-list-algorithm","date":"2017-12-26T05:52:13.000Z","updated":"2017-12-27T10:36:15.000Z","comments":true,"path":"2017/12/top-list-algorithm.html","link":"","permalink":"https://cvno.github.io/2017/12/top-list-algorithm.html","excerpt":"问题现在有n个数（n&gt;10000），设计算法，按大小顺序得到前10m大的数。","text":"问题现在有n个数（n&gt;10000），设计算法，按大小顺序得到前10m大的数。 应用场景：榜单TOP 10 解决方法 先排序，取前 10 个数 O(nlogn) 只留前 10 个数，开一个长度为 10 的列表，用插入排序取出 10 个数，来一个数和列表最后一个数比较，如果比它更小就扔掉 O(nm)不适用与 m 特别大的时候 堆 O(nlogm) 用堆解决思路： 取列表前m个元素建立一个小根堆。堆顶就是目前第m大的数。 依次向后遍历原列表，对于列表中的元素，如果小于堆顶，则忽略该元素；如果大于堆顶，则将堆顶更换为该元素，并且对堆进行一次调整； 遍历列表所有元素后，倒序弹出堆顶。 12345678910111213141516171819202122232425262728293031323334353637def sift(data, low, high): \"\"\" 调整函数 data: 列表 low：待调整的子树的根位置 high：待调整的子树的最后一个节点的位置 \"\"\" i = low j = 2 * i + 1 tmp = data[i] # i指向空位置 while j&lt;=high: #领导已经撸到底了 if j != high and data[j] &lt; data[j+1]: j += 1 #j指向数值大的孩子 if tmp &lt; data[j]: #如果小领导比撸下来的大领导能力值大 data[i] = data[j] i = j j = 2*i+1 else: break #撸下来的领导比候选的领导能力值大 data[i] = tmpdef topn(li, n): heap = li[0:n] # 建堆 for i in range(n // 2 - 1, -1, -1): sift(heap, i, n - 1) # 遍历 for i in range(n, len(li)): if li[i] &gt; heap[0]: heap[0] = li[i] sift(heap, 0, n - 1) # 出数 for i in range(n - 1, -1, -1): heap[0], heap[i] = heap[i], heap[0] sift(heap, 0, i - 1) Python内置模块——heapq 12345678910111213import heapq# 利用heapq模块实现堆排序def heapsort(li): h = [] for value in li: heapq.heappush(h, value)# 建堆, 并自动排序 return [heappop(h) for i in range(len(h))]heapsort([6,8,1,9,3,0,7,2,4,5]) # [0,2,1,3,5,6,7,9,4,8]# ============== 分割线 ==============# 利用heapq模块实现取top-kheapq.nlargest(100, li) 优先队列：一些元素的集合，POP操作每次执行都会从优先队列中弹出最大（或最小）的元素。 堆——优先队列 参考 http://python.usyiyi.cn/translate/python_352/library/heapq.html 1234567# 位运算# &gt;&gt; 除以22 &gt;&gt; 1 # 1 4 &gt;&gt; 1 # 28 &gt;&gt; 1 # 4# &lt;&lt; 乘以 22 &lt;&lt; 1 # 4","categories":[],"tags":[{"name":"heapq","slug":"heapq","permalink":"https://cvno.github.io/tags/heapq/"},{"name":"nlargest","slug":"nlargest","permalink":"https://cvno.github.io/tags/nlargest/"}]},{"title":"数据结构：树","slug":"data-structure-tree","date":"2017-12-25T07:04:18.000Z","updated":"2018-01-09T06:58:34.000Z","comments":true,"path":"2017/12/data-structure-tree.html","link":"","permalink":"https://cvno.github.io/2017/12/data-structure-tree.html","excerpt":"","text":"树 是一种数据结构（如：目录结构） 是一种可以递归定义的数据结构 是由 n 个节点组成的集合 如果 n=0 ，那么是一颗空树 如果 n&gt;0 ，那么存在 1 个节点作为树的根节点，其他节点可以分为 m 个集合，每个集合本身又是一棵树。 概念： 根节点（最顶端的节点）、叶子节点（没有孩子的节点，结构的最末端） 树的深度／高度（也就是树的层数） 节点度（也就是这个节点分了多少叉） 树的度（所有节点度的最大值） 孩子节点/父节点（看字面理解） 子树（根节点的字节点都是独立的树） 二叉树度不超过 2 的树（节点最多有两个叉），它的孩子是有顺序的：左孩子，右孩子。 重点：满二叉树，完全二叉树 二叉树的存储方式 链式存储方式 顺序存储方式（列表） 面向对象的存储方式 父节点和左孩子节点的编号下标有什么关系？ 0-1 1-3 2-5 3-7 4-9规律：i = 2i+1 父节点和右孩子节点的编号下标有什么关系？ 0-2 1-4 2-6 3-8 4-10规律：i = 2i+2 比如，我们要找根节点左孩子的左孩子：（0*2+1）*2+1 = 3 （下标） 所以是6 面向对象的存储方式1234567891011121314151617181920212223242526class BinTreeNode: def __init__(self, data): self.data = data self.lchild = None self.rchild = Nonek = BinTreeNode('K')g = BinTreeNode('G')c = BinTreeNode('C')a = BinTreeNode('A')b = BinTreeNode('B')d = BinTreeNode('D')e = BinTreeNode('E')f = BinTreeNode('F')h = BinTreeNode('H')root = aa.lchild = ba.rchild = eb.lchild = hb.rchild = ff.lchild = de.rchild = cc.lchild = kc.rchild = g 前序遍历 12345678910def PreBianli(root): p = root if p: print(p.data, end=' ') PreBianli(p.lchild) PreBianli(p.rchild)# PreBianli(root) # A B H F D E C K G 前序遍历 中序遍历 1234567def MidBianli(root): p = root if p: MidBianli(p.lchild) print(p.data, end=' ') MidBianli(p.rchild)# MidBianli(root) # H B D F A E K C G 中序遍历 后序遍历 1234567def PostBianli(root): p = root if p: PostBianli(p.lchild) PostBianli(p.rchild) print(p.data, end=' ')# PostBianli(root) # H D F B K G C E A 后序遍历 在根据任意两个序列来推测第三个序列的时候，有中序比较好推测，因为能一眼看出二叉树的根 层级遍历1234567891011121314def LevelBianli(root): curLevel = [root] nextLevel = [] while len(curLevel)&gt;0: for node in curLevel: print(node.data, end=' ') if node.lchild: nextLevel.append(node.lchild) if node.rchild: nextLevel.append(node.rchild) curLevel = nextLevel nextLevel = []LevelBianli(root) # A B E H F C D K G 二叉树小结 二叉树是度不超过 2 的树 满二叉树与完全二叉树 （完全）二叉树可以用列表来存储，通过规律可以从父亲找到孩子或者孩子找到父亲 二叉树遍历方式 : 前序遍历 中序遍历 后序遍历","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://cvno.github.io/categories/数据结构/"}],"tags":[{"name":"树","slug":"树","permalink":"https://cvno.github.io/tags/树/"},{"name":"二叉树","slug":"二叉树","permalink":"https://cvno.github.io/tags/二叉树/"}]},{"title":"递归","slug":"recursion","date":"2017-12-22T12:48:26.000Z","updated":"2017-12-25T07:19:29.000Z","comments":true,"path":"2017/12/recursion.html","link":"","permalink":"https://cvno.github.io/2017/12/recursion.html","excerpt":"","text":"在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。 特点： 调用自身 结束条件 1234567891011121314151617181920212223242526def func1(x): print(x) func1(x-1)# func1(3) # 死递归 没有结束条件def func2(x): if x &gt; 0: print(x) func2(x+1)# func2(3) # 3,4,5,6... 有结束条件，如果是正数还是会陷入死递归def func3(x): if x &gt; 0: print(x) func3(x-1)# func3(3) # 3,2,1 有结束条件def func4(x): if x &gt; 0: func4(x-1) print(x)# func4(3) # 1,2,3 有结束条件 递归效率不高，递归层次过多会导致栈溢出（在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出） 练习 123456789def func(depth): if depth == 0: print('我的小鲤鱼',end='') # 取消换行 else: print('抱着',end='') func(depth-1) print('的我',end='')func(3) # 抱着抱着抱着我的小鲤鱼的我的我的我 123456789101112131415161718192021# 利用递归函数计算阶乘# N! = 1 * 2 * 3 * ... * Ndef fact(n): if n == 1: return 1 return n * fact(n-1)print('fact(1) =', fact(1))print('fact(5) =', fact(5))print('fact(10) =', fact(10))# 利用递归函数移动汉诺塔:def move(n, a, b, c): if n == 1: print('move', a, '--&gt;', c) else: move(n-1, a, c, b) move(1, a, b, c) move(n-1, b, a, c)move(4, 'A', 'B', 'C')","categories":[{"name":"算法","slug":"算法","permalink":"https://cvno.github.io/categories/算法/"}],"tags":[]},{"title":"常用排序算法","slug":"list-algorithm","date":"2017-12-22T07:22:38.000Z","updated":"2017-12-29T08:40:55.000Z","comments":true,"path":"2017/12/list-algorithm.html","link":"","permalink":"https://cvno.github.io/2017/12/list-algorithm.html","excerpt":"","text":"重点: 有序区 无序区 冒泡排序（BUB） 列表每两个相邻的数, 如果前边的比后边的大, 那么交换这两个数 冒泡排序算法的流程如下： 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 关键点: 趟, 无序区 code1234567891011121314# O(n²) 时间复杂度def bubble_sort(li): if len(li) &lt;= 1: return li for i in range(len(li)-1): # i 是趟 for j in range(len(li)-i - 1): # j 是指针 if li[j] &gt; li[j+1]: li[j], li[j+1] = li[j+1] , li[j] return lili = list(range(10000))import random as rdrd.shuffle(li) # 打乱顺序print(li)print(bubble_sort(li)) 优化版123456789101112def bubble_sort(li): if len(li) &lt;= 1: return li for i in range(len(li) - 1): # i 是趟 exchange = Flase for j in range(len(li) - i - 1): # j 是指针 if li[j] &gt; li[j + 1]: li[j], li[j + 1] = li[j + 1], li[j] exchange = True if not exchange: break return li 空间时间复杂度 O(1) 最坏时间复杂度 O(n²) 最优时间复杂度 O(n) 平均时间复杂度 O(n²) 选择排序（SEL）每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。 123456789101112131415def select_sort(li): for i in range(len(li) - 1): # i 是趟 min_doc = i # 找i位置到最后位置范围内最小的数 for j in range(i, len(li)): # i可以换成i+1,省去和自己比 if li[j] &lt; li[min_doc]: min_doc = j # 和无序区第一个数作交换 # 可以加上 i==min_loc 的判断,省去和自己换 if min_doc != i: li[min_doc], li[i] = li[i], li[min_doc] ''' i, j, min_doc 都是下标 ''' return li 空间时间复杂度 O(1) 最坏时间复杂度 O(n²) 最优时间复杂度 O(n²) 平均时间复杂度 O(n²) 插入排序（INS）插入排序每次取出数组后半部分的第一个元素，在排好序的前半部分中，为其找到最合适的位置并进行插入(扑克牌) 列表被分为有序区和无序区两个部分。最初有序区只有一个元素。 每次从无序区选择一个元素，插入到有序区的位置，直到无序区变空。 插入排序算法的流程如下： 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果该元素（已排序）大于新元素，将该元素移到下一位置 重复步骤 3，直到找到已排序的元素小于或者等于新元素的位置 将新元素插入到该位置后 重复步骤 2~5 关键点： 摸到的牌 手里的牌 (有序) code1234567891011def insert_sort(li): if len(li) == 1: return li for i in range(1, len(li)): # i代表每次摸到的牌的下标 tmp = li[i] j = i - 1 # j代表手里最后一张牌的下标 while j &gt;= 0 and tmp &lt; li[j]: # 摸到的牌比手牌最后的牌小 li[j + 1] = li[j] # 把最大的手牌往后挪动 j -= 1 li[j + 1] = tmp # 摸到的牌比手牌最后的牌大 return li 空间时间复杂度 O(1) 最坏时间复杂度 O(n²) 最优时间复杂度 O(n²) 平均时间复杂度 O(n²) 快速排序（QUI）博主看动图不是很理解, 建议看 这里 快速排序算法的流程如下： 取一个元素p（第一个元素），使元素p归位； 列表被p分成两部分，左边都比p小，右边都比p大； 递归完成排序。 关键点： 整理(让元素归位) 递归 1234567891011121314151617181920212223242526272829def partition(data, left, right): ''' partition:归位函数 右手左手一个慢动作 右手左手慢动作重播 ''' tmp = data[left] # 取基准数 while left &lt; right: # 如果需要降序排序的话, 就把 data[right] &gt;= tmp 中的小于等于改为大于等于 while left &lt; right and data[right] &gt;= tmp: right -= 1 # 左移 if left &lt; right: # 如果上面的循环是因为找到了 right 小于 tmp 的数而跳出循环 data[left] = data[right] # 把小于 tmp 的这个元素放到 tmp 的位置上 # 如果需要降序排序的话, 就把 data[right] &gt;= tmp 中的大于等于改为小于等于 while left &lt; right and data[left] &lt;= tmp: left += 1 # 右移 data[right] = data[left] # 把大于 tmp 的这个元素放到 tmp 的位置上 data[left] = tmp # 那个 mid 回来 return left def _quick_sort(data, left, right): if left &lt; right: mid = partition(data, left, right) _quick_sort(data, left, mid - 1) _quick_sort(data, mid + 1, right)@cal_timedef quick_sort(data): return _quick_sort(data,0,len(data)-1) 优化版12345678910111213141516171819# 来自知乎 @风满楼def quick_sort(lists, left, right): if left &gt; right: return lists low, high = left, right key = lists[left] # key即是基准数 while left &lt; right: while left &lt; right and lists[right] &gt;= key: right -= 1 # 左移 lists[left] = lists[right] while left &lt; right and lists[left] &lt;= key: left += 1 # 右移 lists[right] = lists[left] lists[right] = key quick_sort(lists, low, left - 1) quick_sort(lists, right + 1, high) return listsquick(data,0,len(data)-1) 问题某些极端的情况下复杂度非常高, 如： 19 8 7 6 5 4 3 2 1 出现的概率不多, 属于极端情况, 解决方法: 选基准的时候随机选一个数与第一个数交换。 空间时间复杂度 根据实现的方式不同而不同 最坏时间复杂度 O(n²) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) PS: 看到一个最狠的快排 12# https://github.com/qiwsir/algorithm/blob/master/quick_sort.mdqs = lambda xs : ( (len(xs) &lt;= 1 and [xs]) or [ qs( [x for x in xs[1:] if x &lt; xs[0]] ) + [xs[0]] + qs( [x for x in xs[1:] if x &gt;= xs[0]] ) ] )[0] 参考资料 Ele - A面 http://bbs.ahalei.com/thread-4419-1-1.html http://blog.csdn.net/v_july_v/article/details/6116297 https://www.zhihu.com/question/26786398 https://hellolynn.hpd.io/2017/08/03/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F-quick-sort/ https://github.com/qiwsir/algorithm/blob/master/quick_sort.md 堆排序（HEAP）堆排序用的是树的结构 堆 大根堆：一棵完全二叉树，满足任一节点都比其孩子节点大 小根堆：一棵完全二叉树，满足任一节点都比其孩子节点小 假设：节点的左右子树都是堆，但自身不是堆 当根节点的左右子树都是堆时，可以通过一次向下的调整来将其变换成一个堆。 堆排序过程: 建立堆 得到堆顶元素，为最大元素 去掉堆顶，将堆最后一个元素放到堆顶，此时可通过一次调整重新使堆有序。 堆顶元素为第二大元素。 重复步骤3，直到堆变空。 构建堆 先从最小的子树开始看, 最后一步看整个的堆; 从最后一个非叶子节点为根的子树开始做调整 挨个出数 code12345678910111213141516171819202122232425262728293031323334def sift(data, low, high): \"\"\" 调整函数 data: 列表 low：待调整的子树的根位置 high：待调整的子树的最后一个节点的位置 \"\"\" i = low j = 2 * i + 1 tmp = data[i] # i指向空位置 while j&lt;=high: #领导已经撸到底了 if j != high and data[j] &lt; data[j+1]: j += 1 #j指向数值大的孩子 if tmp &lt; data[j]: #如果小领导比撸下来的大领导能力值大 data[i] = data[j] i = j j = 2*i+1 else: break #撸下来的领导比候选的领导能力值大 data[i] = tmpdef heap_sort(data): n = len(data) # 建堆 从最后一个非叶子节点所以是 -1(2) 列表倒序 # n//2-1 找最后一个非叶子节点 # -1(1) 顾前不顾后 for i in range(n//2-1, -1, -1): sift(data, i, n - 1) # 这里的 n-1 是把所有子树的 high 都设置成整个堆的 high # 挨个出数 for high in range(n - 1, -1, -1): data[0], data[high] = data[high], data[0] sift(data, 0, high - 1) 空间时间复杂度 O(n)，O(1) 最坏时间复杂度 O(nlogn) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 引用 数据结构：树 https://www.cnblogs.com/chengxiao/p/6129630.html http://bubkoo.com/2014/01/14/sort-algorithm/heap-sort/ http://wuchong.me/blog/2014/02/09/algorithm-sort-summary/ 归并排序（MER）归并排序思路: 分解：将列表越分越小，直至分成一个元素。 一个元素是有序的。 合并：将两个有序列表归并，列表越来越大。 递归地将数组划分为两部分 直到两个子数组元素都为1时，返回并将两个数组进行排序融合 逐步返回，并递归融合，最终使得数组有序 code1234567891011121314151617181920212223242526272829def merge(data, low, mid, high): '''一次归并''' i = low j = mid + 1 ltmp = [] # 临时列表 while i &lt;= mid and j &lt;= high: if data[i] &lt;= data[j]: ltmp.append((data[i])) i += 1 else: # data[i] &gt; data[j] ltmp.append(data[j]) j += 1 while i &lt;= mid: ltmp.append(data[i]) i += 1 while j &lt;= high: ltmp.append(data[j]) j += 1 data[low:high + 1] = ltmpdef mergesort(data, low, high): '''归并排序''' if low &lt; high: mid = (low + high) // 2 # 获取中间位置 mergesort(data, low, mid) # 分解左半部分 mergesort(data, mid + 1, high) # 分解右半部分 merge(data, low, mid, high) # 归并 return data 加深理解12345678def func(x): if x &gt; 1: y = x // 2 func(y) func(y) print(y)func(20)# 看最后的输出 画图 或者结合递归 空间时间复杂度 O(n) 最坏时间复杂度 O(nlogn) 最优时间复杂度 O(n) 平均时间复杂度 O(nlogn) 快速排序、堆排序、归并排序 - 小结 三种排序算法的时间复杂度都是O(nlogn) 运行时间: 快速排序 &lt; 归并排序 &lt; 堆排序 三种排序算法的缺点： 快速排序 极端情况下排序效率低 归并排序 需要额外的内存开销 堆排序 在快的排序算法中相对较慢 计数排序（COU） 题: 现在有一个列表，列表中的数范围都在 0 到 100 之间，列表长度大约为 100 万。设计算法在 O(n) 时间复杂度内将列表进行排序。 12345678910111213141516171819def count_sort(data, maxnum = 100): '''计数排序 O(n)''' count = [0 for i in range(maxnum+1)] result = [] for i in data: count[i] += 1 for num,count in enumerate(count): for i in range(count): result.append(num)# 或def count_sort(data, max_num): count = [0 for i in range(max_num + 1)] for num in data: count[num] += 1 i = 0 for num, m in enumerate(count): for j in range(m): data[i] = num i += 1 因为要开额外的内存空间，所以使用并不多。计数排序限定元素不会太大的时候，如：年龄可以使用计数排序 希尔排序（SHE）希尔排序是一种分组插入排序算法。O(1.3n) 以数组元素长度的一半做为初始步长gap，将数组划分为gap个子数组 循环切换遍历子数组，在子数组内分别进行插入排序 将gap更新为gap/2，重复上述步骤1，2，直到gap为1 希尔排序思路： 先取一个正整数 d1(d1 &lt; n)，把全部记录分成 d1 个组，所有距离为 d1 的倍数的记录看成一组，然后在各组内进行插入排序 然后取 d2(d2 &lt; d1) 重复上述分组和排序操作；直到取 di = 1(i &gt;= 1) 位置，即所有记录成为一个组，最后对这个组进行插入排序。一般选 d1 约为 n/2，d2 为 d1 /2， d3 为 d2/2 ，…， di = 1。 希尔排序每趟并不使某些元素有序，而是使整体数据越来越接近有序；最后一趟排序使得所有数据有序。 1234567891011121314151617# 修改插入排序def insert_sort_gap(data, gap): for i in range(gap, len(data)): tmp = data[i] j = i - gap while j &gt;= 0 and tmp &lt; data[j]: data[j + gap] = data[j] j = j - gap data[j + gap] = tmpdef shell_sort(data): '''希尔排序''' d = len(data) // 2 while d &gt; 0: insert_sort_gap(data,d) d = d // 2 return data 优化版12345678910111213def shell_sort(data): n = len(data) gap = len(data) // 2 while gap &gt; 0: for i in range(gap, n): tmp = data[i] j = i - gap while j &gt;= 0 and tmp &lt; data[j]: data[j + gap] = data[j] j -= gap data[j + gap] = tmp gap = gap // 2 return data 后记排序算法指标 排序的稳定性排序关键字相同的情况下，对象的相对位置不变 计时装饰器12345678def cal_time(func): def wrapper(*args, **kwargs): t1 = time.time() x = func(*args, **kwargs) t2 = time.time() print(\"%s running time %s secs.\" % (func.__name__, t2 - t1)) return x return wrapper 参考资料 博客部分图片截取自 https://visualgo.net/zh/sorting http://bubkoo.com http://chenyvehtung.github.io/2017/02/26/sort-algorithms.html 维基百科-排序算法","categories":[{"name":"算法","slug":"算法","permalink":"https://cvno.github.io/categories/算法/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://cvno.github.io/tags/Python/"}]},{"title":"hexo: ERROR Process failed: _posts/*","slug":"hexo-ERROR-Process-failed-posts","date":"2017-12-18T06:49:12.000Z","updated":"2017-12-20T13:18:41.000Z","comments":true,"path":"2017/12/hexo-ERROR-Process-failed-posts.html","link":"","permalink":"https://cvno.github.io/2017/12/hexo-ERROR-Process-failed-posts.html","excerpt":"文章的格式出现错误了","text":"文章的格式出现错误了 错误提示 1234$ hexo sERROR Process failed: _posts/*Error at ..... 原因 123title: Hexodate: 2017-12-13 12:21:33tags:Hexo #tags冒号后面应当有个空格,其他地方也应当注意 正确格式(加上那个空格就好了) 123title: Hexodate: 2017-12-13 12:21:33tags: Hexo 参考资料 http://shitaibin.github.io/2015/12/13/hexo-errors/","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://cvno.github.io/tags/hexo/"}]},{"title":"Python:消息队列Rabbitmq基本使用","slug":"rabbitmq-apply","date":"2017-12-18T06:24:45.000Z","updated":"2017-12-20T13:24:14.000Z","comments":true,"path":"2017/12/rabbitmq-apply.html","link":"","permalink":"https://cvno.github.io/2017/12/rabbitmq-apply.html","excerpt":"为什么用Rabbitmq instead of python queue ?","text":"为什么用Rabbitmq instead of python queue ? 是因为python queue 不能跨进程 队列的作用: 1. 存储消息、数据 2. 保证消息顺序 3. 保证数据的交付 12345678910111213141516171819# 斐波那契数列1 1 2 3 5 8 13 ...# 启动rabbitmq，并验证启动情况 rabbitmq-server --detached &amp;ps aux |grep rabbitmq# 以服务的方式启动service rabbitmq-server start# 启用维护插件rabbitmq-plugins enable rabbitmq_management # 重启service rabbitmq-server restart# erroepika.exceptions.ProbableAuthenticationError# 解决方法# 写入信息 并保存/关闭防火墙 'systemctl stop filewallf'vim /etc/rabbitmq/rabbitmq.config[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;].# 查看当前队列rabbitmqctl list_queues 基本使用实现发送端1234567891011121314151617181920212223import pika# 创建连接connection = pika.BlockingConnection(pika.ConnectionParameters('10.211.55.10'))channel = connection.channel()# 声明消息队列channel.queue_declare(queue='hello')# 发送消息到上面声明的hello队列，# 其中exchange表示交换器，能精确指定消息应该发送到哪个队列，# routing_key设置为队列的名称，# body就是发送的内容，channel.basic_publish(exchange='',routing_key='hello',body='Hello World!')print('[x] Sent \"Hello World!\"')# sh命令# 用 rabbitmqctl list_queues 查看队列'''Listing queueshello 1''' 接收端1234567891011121314151617181920212223import pika# 创建连接connection = pika.BlockingConnection(pika.ConnectionParameters('10.211.55.10'))channel = connection.channel()# 声明消息队列channel.queue_declare(queue='hello')# 接收消息 回调函数def callbcak(ch,method,properties,body): print(\"Received %r\"%(body))# 告诉rabbitmq使用callback来接收信息channel.basic_consume(callbcak,queue='hello',no_ack=True)#开始接收信息，并进入阻塞状态，队列里有信息才会调用callback进行处理。按ctrl+c退出。channel.start_consuming()# 终端会阻塞住'''Received b'Hello World!'''' 工作队列消息不丢失生产者12345for i in range(5): msg = ' '.join(sys.argv[1:])or 'Hello World! %s' % time.time() channel.basic_publish(exchange='', routing_key='hello', body=bytes(msg,encoding='utf8'),) 消费者 no_ack=False 消费者退出不消息不丢失 12345# 修改回调函数def callbcak(ch, method, properties, body): print(\"Received %r\" % (body)) time.sleep(5) print(\"[x] Done\") 消息持久化 消息持久化存储, 虽然消息反馈机制，但是如果rabbitmq自身挂掉的话，那么任务还是会丢失。所以需要将任务持久化存储起来。声明持久化存储： 12# 原队列channel.queue_declare(queue='hello', durable=True) 但是这个程序会执行错误，因为hello这个队列已经存在，并且是非持久化的，rabbitmq不允许使用不同的参数来重新定义存在的队列。重新定义一个队列 12# 重新定义一个队列channel.queue_declare(queue='task_queue', durable=True) 在发送任务的时候，用delivery_mode=2来标记任务为持久化存储： 123456channel.basic_publish(exchange='', routing_key=\"task_queue\", body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent )) 公平调度prefetch_count = 1 虽然每个工作者是依次分配到任务，但是每个任务不一定一样。可能有的任务比较重，执行时间比较久；有的任务比较轻，执行时间比较短。如果能公平调度就最好了，使用basic_qos设置prefetch_count=1，使得rabbitmq不会在同一时间给工作者分配多个任务，即只有工作者完成任务之后，才会再次接收到任务。 1channel.basic_qos(prefetch_count=1) new_task.py完整代码 发送者/生产者 123456789101112131415161718import pikaimport sysconnection = pika.BlockingConnection(pika.ConnectionParameters( host='10.211.55.10'))channel = connection.channel()channel.queue_declare(queue='task_queue', durable=True)message = ' '.join(sys.argv[1:]) or \"Hello World!\"channel.basic_publish(exchange='', routing_key='task_queue', body=message, properties=pika.BasicProperties( delivery_mode=2, # make message persistent ))print(\" [x] Sent %r\" % (message,))connection.close() worker.py完整代码 接受者/消费者 123456789101112131415161718192021import pikaimport timeconnection = pika.BlockingConnection(pika.ConnectionParameters(host='10.211.55.10'))channel = connection.channel()channel.queue_declare(queue='task_queue', durable=True)print(' [*] Waiting for messages. To exit press CTRL+C')def callback(ch, method, properties, body): print(\" [x] Received %r\" % (body,)) time.sleep(6) print(\" [x] Done\",ch.basic_ack(delivery_tag=method.delivery_tag))channel.basic_qos(prefetch_count=1)channel.basic_consume(callback, queue='task_queue')channel.start_consuming() 广播广播交换机的工作原理：消息发送端先将消息发送给交换机，交换机再将消息发送到绑定的消息队列，而后每个接收端都能从各自的消息队列里接收到信息。 消费者/接收端receive.py代码分析和最早的receive.py相比，主要是做了两个改动： 定义交换机 不使用hello队列了，随机生成一个临时队列，并绑定到交换机上 123456789101112131415161718192021222324import pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( '10.211.55.10'))channel = connection.channel()# 定义交换机channel.exchange_declare(exchange='messages', type='fanout')# 随机生成队列，并绑定到交换机上# 参数'exclusive=True'表示当接收端退出时，销毁临时产生的队列，这样就不会占用资源。result = channel.queue_declare(exclusive=True)queue_name = result.method.queuechannel.queue_bind(exchange='messages', queue=queue_name)def callback(ch, method, properties, body): print(\" [x] Received %r\" % (body,))channel.basic_consume(callback, queue=queue_name, no_ack=True)print(' [*] Waiting for messages. To exit press CTRL+C')channel.start_consuming() 执行rabbitmqctl list_queues 1234task_queue 0hello 5# 定义了交换机amq.gen-K0M17k_3LVYO0b7m0s-K1g 0 生产者/发送端send.py代码分析和最早的send.py相比，也只做了两个改动： 定义交换机 不是将消息发送到hello队列，而是发送到交换机 12345678910111213141516import pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( '10.211.55.10'))channel = connection.channel()# 定义交换机# type='fanout' 表示广播的意思channel.exchange_declare(exchange='messages', type='fanout')# 将消息发送到交换机# basic_publish方法的参数exchange被设定为相应交换机，# 因为是要广播出去，发送到所有队列，所以routing_key就不需要设定了。channel.basic_publish(exchange='messages', routing_key='', body='Hello World!')print(\" [x] Sent 'Hello World!'\")connection.close() exchange如果为空，表示是使用匿名的交换机，在上面交换机信息的图片中可以看到有amq.*这样的交换机，就是系统默认的交换机了。routing_key在使用匿名交换机的时候才需要指定，表示发送到哪个队列的意思。第一篇的例子演示了这个功能。 打开另外一个终端，执行send.py，可以观察到receive.py接收到了消息。如果有多个终端执行receive.py，那么每个receive.py都会接收到消息。 组播/路由生产者/send.py代码分析和广播相比，改动点主要在两个方面： 设定交换机的类型（type）为direct。上一篇是设置为fanout，表示广播的意思，会将消息发送到所有接收端，这里设置为direct表示要根据设定的路由键来发送消息。 发送信息时设置发送的路由键。 123456789101112131415161718192021import pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( '10.211.55.10'))channel = connection.channel()# 定义交换机，设置类型为directchannel.exchange_declare(exchange='messages', type='direct')# 定义三个路由键routings = ['warning', 'error']# 将消息依次发送到交换机，并设置路由键for routing in routings: message = '%s message.' % routing channel.basic_publish(exchange='messages', routing_key=routing, body=message) print(message)connection.close() 消费者/receive.py代码分析和广播相比，改动点主要在三个方面： 设定交换机的类型（type）为direct。 增加命令行获取参数功能，参数即为路由键。 将队列绑定到交换机上时，设定路由键。 12345678910111213141516171819202122232425262728293031import pika, sysconnection = pika.BlockingConnection(pika.ConnectionParameters( '10.211.55.10'))channel = connection.channel()# 定义交换机，设置类型为directchannel.exchange_declare(exchange='messages', type='direct')# 从命令行获取路由键参数，如果没有，则设置为inforoutings = sys.argv[1:]if not routings: routings = ['info']# 生成临时队列，并绑定到交换机上，设置路由键result = channel.queue_declare(exclusive=True)queue_name = result.method.queuefor routing in routings: channel.queue_bind(exchange='messages', queue=queue_name, routing_key=routing)def callback(ch, method, properties, body): print(\" [x] Received %r\" % (body,))channel.basic_consume(callback, queue=queue_name, no_ack=True)print(' [*] Waiting for messages. To exit press CTRL+C')channel.start_consuming() 打开两个终端，一个运行代码python receive.py info warning，表示只接收info和warning的消息。另外一个终端运行send.py，可以观察到接收终端只接收到了info和warning的消息。如果打开多个终端运行receive.py，并传入不同的路由键参数，可以看到更明显的效果。 当接收端正在运行时，可以使用rabbitmqctl list_bindings来查看绑定情况。 按规则发送/正则上面路由键/组播的功能，通过设置路由键，可以将消息发送到相应的队列，这里的路由键是要完全匹配，比如info消息的只能发到路由键为info的消息队列。 路由键模糊匹配，就是可以使用正则表达式，和常用的正则表示式不同，这里的话“#”表示所有、全部的意思；“*”只匹配到一个词。看完示例就能明白了。 send.py代码分析因为要进行路由键模糊匹配，所以交换机的类型要设置为topic，设置为topic，就可以使用#，*的匹配符号了。 12345678910111213141516171819202122import pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( '10.211.55.10'))channel = connection.channel()# 定义交换机，设置类型为topicchannel.exchange_declare(exchange='messages', type='topic')# 定义路由键# 四种类型的消息routings = ['happy.work', 'happy.life', 'sad.work', 'sad.life']# 将消息依次发送到交换机，并设定路由键for routing in routings: message = '%s message.' % routing channel.basic_publish(exchange='messages', routing_key=routing, body=message) print(message)connection.close() receive.py代码分析类型要设定为topic就可以了。从命令行接收参数的功能稍微调整了一下，没有参数时报错退出。 123456789101112131415161718192021222324252627282930313233import pika, sysconnection = pika.BlockingConnection(pika.ConnectionParameters( '10.211.55.10'))channel = connection.channel()# 定义交换机，设置类型为topicchannel.exchange_declare(exchange='messages', type='topic')# 从命令行获取路由参数，如果没有，则报错退出routings = sys.argv[1:]if not routings: # print(&gt;&gt; sys.stderr, \"Usage: %s [routing_key]...\" % (sys.argv[0],)) print(sys.stderr, \"Usage: %s [routing_key]...\" % (sys.argv[0],)) exit()# 生成临时队列，并绑定到交换机上，设置路由键result = channel.queue_declare(exclusive=True)queue_name = result.method.queuefor routing in routings: channel.queue_bind(exchange='messages', queue=queue_name, routing_key=routing)def callback(ch, method, properties, body): print(\" [x] Received %r\" % (body,))channel.basic_consume(callback, queue=queue_name, no_ack=True)print(' [*] Waiting for messages. To exit press CTRL+C')channel.start_consuming() 实验运行打开多个终端,分别传入不同的规则,观察结果如: 123python3 receive_topic.py \"#\"python3 receive_topic.py \"happy.*\"python3 receive_topic.py \"*.work\" 难点1、发送信息时，如果不设置路由键，那么路由键设置为”*”的接收端是否能接收到消息？ 发送信息时，如果不设置路由键，默认是表示广播出去，理论上所有接收端都可以收到消息，但是笔者试了下，路由键设置为”*”的接收端收不到任何消息。 只有发送消息时，设置路由键为一个词，路由键设置为”*”的接收端才能收到消息。在这里，每个词使用”.”符号分开的。 2、发送消息时，如果路由键设置为”..”，那么路由键设置为”#.*”的接收端是否能接收到消息？如果发送消息时，路由键设置为一个词呢？ 两种情况，笔者都测试过了，可以的。 3、”a.*.#” 和”a.#”的区别 “a.#”只要字符串开头的一个词是a就可以了，比如a、a.haha、a.haha.haha。而这样的词是不行的，如abs、abc、abc.haha。 “a..#”必须要满足a.的字符串才可以，比如a.、a.haha、a.haha.haha。而这样的词是不行的，如a。 远程结果返回RPCRemote Producre Call处理方法描述： 发送端在发送信息前，产生一个接收消息的临时队列，该队列用来接收返回的结果。其实在这里接收端、发送端的概念已经比较模糊了，因为发送端也同样要接收消息，接收端同样也要发送消息，所以这里笔者使用另外的示例来演示这一过程。 compute.py代码分析12345678910111213141516171819202122232425262728293031323334import pika# 连接rabbitmq服务器connection = pika.BlockingConnection(pika.ConnectionParameters( host='10.211.55.10'))channel = connection.channel()# 定义队列channel.queue_declare(queue='compute_queue')print(' [*] Waiting for n')# 将n值加1def increase(n): return n + 1# 定义接收到消息的处理方法def request(ch, method, properties, body): print(\" [.] increase(%s)\" % (body,)) response = increase(int(body)) # 将计算结果发送回控制中心 ch.basic_publish(exchange='', routing_key=properties.reply_to, body=str(response)) ch.basic_ack(delivery_tag=method.delivery_tag)channel.basic_qos(prefetch_count=1)channel.basic_consume(request, queue='compute_queue')channel.start_consuming() center.py代码分析123456789101112131415161718192021222324252627282930313233343536373839404142import pikaclass Center(object): def __init__(self): self.connection = pika.BlockingConnection(pika.ConnectionParameters( host='10.211.55.10')) self.channel = self.connection.channel() # 定义接收返回消息的队列 result = self.channel.queue_declare(exclusive=True) self.callback_queue = result.method.queue self.channel.basic_consume(self.on_response, no_ack=True, queue=self.callback_queue) # 定义接收到返回消息的处理方法 def on_response(self, ch, method, props, body): self.response = body def request(self, n): self.response = None # 发送计算请求，并声明返回队列 self.channel.basic_publish(exchange='', routing_key='compute_queue', properties=pika.BasicProperties( reply_to=self.callback_queue, ), body=str(n)) # 接收返回的数据 while self.response is None: self.connection.process_data_events() return int(self.response)center = Center()print(\" [x] Requesting increase(30)\")response = center.request(30)print(\" [.] Got %r\" % (response,)) 上面代码定义了接收返回数据的队列和处理方法，并且在发送请求的时候将该队列赋值给reply_to，在计算节点代码中就是通过这个参数来获取返回队列的。 相互关联编号correlation idcorrelation id运行原理： 控制中心发送计算请求时设置correlation id，而后计算节点将计算结果，连同接收到的correlation id一起返回，这样控制中心就能通过correlation id来标识请求。其实correlation id也可以理解为请求的唯一标识码。 示例内容： 控制中心开启多个线程，每个线程都发起一次计算请求，通过correlation id，每个线程都能准确收到相应的计算结果。 compute.py代码分析和上面相比，只需修改一个地方： 将计算结果发送回控制中心时，增加参数correlation_id的设定，该参数的值其实是从控制中心发送过来的，这里只是再次发送回去。代码如下： 123456789101112131415161718192021222324252627282930313233343536import pika# 连接rabbitmq服务器connection = pika.BlockingConnection(pika.ConnectionParameters( host='10.211.55.10'))channel = connection.channel()# 定义队列channel.queue_declare(queue='compute_queue')print(' [*] Waiting for n')# 将n值加1def increase(n): return n + 1# 定义接收到消息的处理方法def request(ch, method, props, body): print(\" [.] increase(%s)\" % (body,)) response = increase(int(body)) # 将计算结果发送回控制中心，增加correlation_id的设定 ch.basic_publish(exchange='', routing_key=props.reply_to, properties=pika.BasicProperties(correlation_id= \\ props.correlation_id), body=str(response)) ch.basic_ack(delivery_tag=method.delivery_tag)channel.basic_qos(prefetch_count=1)channel.basic_consume(request, queue='compute_queue')channel.start_consuming() center.py代码分析控制中心代码稍微复杂些，其中比较关键的有三个地方： 使用python的uuid来产生唯一的correlation_id。 发送计算请求时，设定参数correlation_id。 定义一个字典来保存返回的数据，并且键值为相应线程产生的correlation_id。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import pika, threading, uuid# 自定义线程类，继承threading.Threadclass MyThread(threading.Thread): def __init__(self, func, num): super(MyThread, self).__init__() self.func = func self.num = num def run(self): print(\" [x] Requesting increase(%d)\" % self.num) response = self.func(self.num) print(\" [.] increase(%d)=%d\" % (self.num, response))# 控制中心类class Center(object): def __init__(self): self.connection = pika.BlockingConnection(pika.ConnectionParameters( host='10.211.55.10')) self.channel = self.connection.channel() # 定义接收返回消息的队列 result = self.channel.queue_declare(exclusive=True) self.callback_queue = result.method.queue self.channel.basic_consume(self.on_response, no_ack=True, queue=self.callback_queue) # 返回的结果都会存储在该字典里 self.response = &#123;&#125; # 定义接收到返回消息的处理方法 def on_response(self, ch, method, props, body): self.response[props.correlation_id] = body def request(self, n): corr_id = str(uuid.uuid4()) # 产生 id self.response[corr_id] = None # 发送计算请求，并设定返回队列和correlation_id self.channel.basic_publish(exchange='', routing_key='compute_queue', properties=pika.BasicProperties( reply_to=self.callback_queue, correlation_id=corr_id, ), body=str(n)) # 接收返回的数据 while self.response[corr_id] is None: self.connection.process_data_events() return int(self.response[corr_id])center = Center()# 发起5次计算请求nums = [10, 20, 30, 40, 50]threads = []for num in nums: threads.append(MyThread(center.request, num))for thread in threads: thread.start()for thread in threads: thread.join() 参考资料http://blog.csdn.net/chenjiebin/article/details/8253433","categories":[],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://cvno.github.io/tags/Rabbitmq/"}]},{"title":"密码学基础","slug":"basis-of-cryptography","date":"2017-11-01T12:10:33.000Z","updated":"2017-12-20T13:20:54.000Z","comments":true,"path":"2017/11/basis-of-cryptography.html","link":"","permalink":"https://cvno.github.io/2017/11/basis-of-cryptography.html","excerpt":"平常用的登录密码不叫密码，是登录口令","text":"平常用的登录密码不叫密码，是登录口令 密码有一个加密和解密的过程 video: https://youtu.be/loJ62rvH8aE 古典密码凯撒密码123ABCCDE// 往后移动3位或者多位 非常容易破解 维吉尼亚密码 不知道密钥是非常非常难破解的 RSA 公钥 私钥 12明文--&gt; 公钥 --&gt; 密文密文--&gt; 私钥 --&gt; 明文 基于大数难分解两个质数相乘 12345678910111213p1 = 53p2 = 59n = 3127 # 53 * 59 = 3127# 欧拉函数Φ(n)(p1-1)*(p2-1)= 3016 # fai 小写 φe = 3 # e 和欧拉函数互质 只要互质随便取# 公钥是 n，ed = (k*φ(n)+1)/e = 2011 # 私钥 (2**3016+1)/3 = 2011# 验证m = 89 # 加密信息 c = (m**e)%n = 1394 # 密文 (89**3)%3127 = 1394明文 = (x**d)%n = 89 # 明文 (1394**2011)%3127 = 89 扩展: 费马小定理来验证.","categories":[],"tags":[]},{"title":"列表查找","slug":"list-search","date":"2017-09-21T04:09:36.000Z","updated":"2017-12-21T13:39:39.000Z","comments":true,"path":"2017/09/list-search.html","link":"","permalink":"https://cvno.github.io/2017/09/list-search.html","excerpt":"","text":"顺序查找 从列表第一个元素开始，顺序进行搜索，直到找到为止。 12345678910li = [1,2,3]index(1) # 顺序查找# 顺序查找 ipython O(n) 复杂度import randomn = 10000li = list(range(n))random.shuffle(li)%timeit li.index(3200)#221 µs ± 11.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 二分查找 只能用于有序列表 从有序列表的候选区data[0:n]开始，通过对待查找的值与候选区中间值的比较，可以使候选区减少一半。O(logn) 复杂度 12345678910111213141516171819202122232425262728293031323334353637# 二分查找# 循环版本# def bin_search(li,low,high):def bin_search(li, val): '''循环二分 时间复杂度 O(logn)''' low = 0 high = len(li) - 1 while low &lt;= high: mid = (low + high) // 2 if li[mid] == val: return mid elif li[mid] &lt; val: low = mid + 1 else: # &gt; high = mid - 1 return None# 5.6 µs ± 441 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)# 递归版本 递归需要切换进出栈def bin_search_rec(data_set,value,low,high): ''' 尾递归 和 非递归的效率基本一样 ''' if low &lt;= high: mid = (low+high) // 2 if data_set[mid] == value: return mid elif data_set[mid] &gt; value: # 尾递归不用切换出栈 return bin_search_rec(data_set,value,low,mid-1) else: return bin_search_rec(data_set,value,mid+1,high) else: return# %timeit l1.index(3200)# l1.sort() # 排序# %timeit bin_search(l1,3200)print(bin_search(l1,4000)) 刷题：Letcode34. Search for a Range (二分查找升级版)1. Two Sum 习题1 34. Search for a Range (二分查找升级版) 12345678910111213141516171819def bin_search(li, val): '''循环二分 时间复杂度 O(logn)''' low = 0 high = len(li) - 1 while low &lt;= high: mid = (low + high) // 2 if li[mid] == val: a = mid b = mid while li[a] = value and a &gt;= 1: a -= 1 while li[b] = value and b &lt; len(li): # b &lt;= len(li) - 1 b += 1 return (a+1,b-1) elif li[mid] &lt; val: low = mid + 1 else: # &gt; high = mid - 1 return None 2 . 1. Two Sum 12345678910def two_sum(nums, target): l = len(nums) for i in range(l): for j in range(i+1,l): print(nums[i],nums[j]) if nums[i] + nums[j] == target: return (i,j) return None print(two_sum([2, 7, 11, 15],9)) 或者 1234567891011121314151617181920212223242526272829303132333435def bin_search(data_set, value): low = 0 high = len(data_set) - 1 while low &lt;= high: mid = (low + high) // 2 if data_set[mid] == value: return mid elif data_set[mid] &gt; value: high = mid - 1 else: low = mid + 1def two_sum_2(li, target): li.sort() for i in range(len(li)): b = target - li[i] j = bin_search(li, b) if j != None and i != j: return i, jprint(two_sum_2([2, 7, 11], 14))def two_sum_3(li, target): li.sort() # nlogn i = 0 j = len(li) - 1 while i&lt;j: sum = li[i]+li[j] if sum &gt; target: j-=1 elif sum &lt; target: i+=1 else: #sum==target return (i,j) return None 扩展1. Two Sum 如果是 3 个数 就把第一个数固定, 后面的列表用 two_sum_3 来计算 如果这样时间复杂度nlogn + n²最终的时间复杂度是 n² 如果用二分查找, 就需要先排序, 定住两个数, 排序(nlogn) + 定住两个数(n²) 二分(n²logn) 最终的复杂度是 n²logn","categories":[{"name":"算法","slug":"算法","permalink":"https://cvno.github.io/categories/算法/"}],"tags":[]},{"title":"时间复杂度与空间复杂度","slug":"algorithm-complexity","date":"2017-09-20T04:11:51.000Z","updated":"2017-12-21T13:39:49.000Z","comments":true,"path":"2017/09/algorithm-complexity.html","link":"","permalink":"https://cvno.github.io/2017/09/algorithm-complexity.html","excerpt":"算法的时间复杂度是一个函数，它定量描述了该算法的运行时间。用来评估算法运行效率的单位。","text":"算法的时间复杂度是一个函数，它定量描述了该算法的运行时间。用来评估算法运行效率的单位。 时间复杂度 时间复杂度是用来估计算法运行时间的一个式子（单位） T(n) = O(n^2) 按数量级递增排列，常见的时间复杂度有：常数阶O(1),对数阶O(log2n),线性阶O(n), 线性对数阶O(nlog2n),平方阶O(n2)，立方阶O(n3),…， k次方阶O(nk),指数阶O(2n)。随着问题规模n的不断增大，上述时间复杂度不断增大，算法的执行效率越低。 一般来说,时间复杂度高的算法比复杂度底的算法慢. 12345678910111213print('Hello World') # O(1)for i in range(n): # O(n) print('Hello World')for i in range(n): # O(n²) for i in range(n): print('Hello World')for i in range(n): # O(n³) for j in rnage(n): for k in range(n): print('Hello World') 如何一眼判断时间复杂度 循环减半的过程 –&gt;O(logn) 几次循环就是n的几次方的复杂度 时间复杂度排序 常见的时间复杂度 1O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n²)&lt;O(n²logn)&lt;O(n³) 不常见的时间复杂度 1O(n!) O(2n) O(nn) … 几秒钟/O(1) 几分钟/O(n) 几小时/O(n²) // 2 平方 高级： 函数 见进阶 判断时间复杂度123456789101112131415# 1 O(1) 时间复杂度print('Hello World')print('Hello Python')print('Hello Algorithm')# 2 O(n²) 时间复杂度for i in range(n): print('Hello World') for i in range(n): print('Hello World')# 3 O(n²) 时间复杂度for i in range(n): for j in range(i): print('Hello World') 1234567# 以2为底64的对数n = 64while n &gt; 1: print(n) n = n // 2# 时间复杂度 O(log2n) / O(logn)# 每次少一半 空间复杂度 用来评估算法内存占用大小的式子 S(n) = O(n^2) 表示内存占用时间复杂度比空间复杂度更重要 空间换时间 一个列表就是 O(n)二维列表复杂度就是 O(n²)…","categories":[{"name":"算法","slug":"算法","permalink":"https://cvno.github.io/categories/算法/"}],"tags":[]},{"title":"Charles: Response 出现乱码","slug":"Charles-Response-error","date":"2017-09-18T13:19:42.000Z","updated":"2017-12-20T13:18:41.000Z","comments":true,"path":"2017/09/Charles-Response-error.html","link":"","permalink":"https://cvno.github.io/2017/09/Charles-Response-error.html","excerpt":"使用 Charles 抓 https 包的时候, Reponse 出现乱码","text":"使用 Charles 抓 https 包的时候, Reponse 出现乱码 系统环境: MAC软件版本: 4.2.1浏览器: Google Chrome 原因没有信任 Charles 的证书,信任 Charles 的证书就好了 解决方法安装 Charles 证书Help &gt; SSL Proxying &gt; Install Charles Root Certificate 信任 Charles 证书安装完成后会自动弹出钥匙串,找到 Charles 的证书信任即可 Charles 设置Proxy &gt; SSL Proxying Settings ok后记发布这篇文章的时候问题已经被解决,但是没有问题截图,有时间的话再补上.","categories":[],"tags":[{"name":"Charles","slug":"Charles","permalink":"https://cvno.github.io/tags/Charles/"}]}]}